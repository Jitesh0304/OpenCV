{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff013204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# distance from camera to object(object) measured\n",
    "# centemeter\n",
    "KNOW_DISTANCE = 10\n",
    "\n",
    "# width of the object in real\n",
    "# centimeter\n",
    "KNOWN_WIDTH = 3.4\n",
    "\n",
    "## some colors \n",
    "Green = (0,255,0)\n",
    "Red = (0,0,255)\n",
    "White = (255,255,255)\n",
    "Black = (0,0,0)\n",
    "\n",
    "## define fonts\n",
    "fonts = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "\n",
    "              ## here we will find the focal length \n",
    "def Focal_length_finder(measured_distance, real_width, width_in_ref_image):\n",
    "    \n",
    "    focal_length = (width_in_ref_image * measured_distance) / real_width\n",
    "    \n",
    "    return focal_length\n",
    "\n",
    "\n",
    "              ## distance estimator fuction\n",
    "def Distance_finder(Focal_length, real_width_object , object_width_in_frame):\n",
    "\n",
    "    distace = (real_width_object * Focal_length) / object_width_in_frame\n",
    "\n",
    "    return distace\n",
    "\n",
    "\n",
    "\n",
    "def object_data(image):\n",
    "\n",
    "    object_width = 0\n",
    "    \n",
    "        # convert the image to grayscale, blur it, and detect edges\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 35, 125)\n",
    "    \n",
    "        # find the contours in the edged image and keep the largest one;                          \n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    \n",
    "        # we'll assume that this is our object in the image \n",
    "        ## this function use for sorting the values of the contour in a serial manner so taht we can use those values\n",
    "        ## for further\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        # A contour of an image is a curve joining all the continuous points along the boundary, \n",
    "        # having the same color or intensity. Contours are used for shape analysis and object detection and recognition etc.\n",
    "        # To compute the area and perimeter of an object, we first detect the contour of the object and then apply cv2.    \n",
    "    c = max(cnts, key = cv2.contourArea)\n",
    "\n",
    "        # compute the bounding box of the of the object region and return it as 4_cornors of rectangle\n",
    "        # (center(x, y), (width, height), angle of rotation) = cv2.minAreaRect(points)\n",
    "    rec = cv2.minAreaRect(c)\n",
    "    \n",
    "        ## box contain all 4_lines dimensions (which means the 4 lines of a rectangle coordinates)\n",
    "    box = cv2.cv.BoxPoints(rec) if imutils.is_cv2() else cv2.boxPoints(rec) \n",
    "            \n",
    "        # np.int0() .... this helps to convert all the float type values inside the np.array to integer type\n",
    "    box = np.int0(box)     \n",
    "\n",
    "        ## draw line or connect all four points of the contours\n",
    "    cv2.drawContours(image, [box], -1, Red, 2)\n",
    "    \n",
    "    \n",
    "        ## we actually want to return the width of the object(pixel)\n",
    "    return int(rec[1][0])\n",
    "\n",
    "\n",
    "\n",
    "    ## reading reference image from directory \n",
    "reference_image = cv2.imread('photo1.jpeg')\n",
    "\n",
    "    ## find the object width(pixels) in the reference_image\n",
    "ref_image_object_width = object_data(reference_image)\n",
    "\n",
    "    ## get the focal by calling \"focal_length_finder\"\n",
    "    ## object width in reference(pixels)\n",
    "    ## known distance in (centimeter)\n",
    "    ## known width in (centimeter)\n",
    "Focal_length_found = Focal_length_finder(KNOW_DISTANCE, KNOWN_WIDTH, ref_image_object_width)\n",
    "\n",
    "\n",
    "    ## show the reference image \n",
    "cv2.imshow('window', reference_image)\n",
    "\n",
    "    ## initialize the camera object so that we can get frame from it\n",
    "cap = cv2.VideoCapture('video1.mp4')\n",
    "\n",
    "    ## looping through frame, incoming from camera / or / video  \n",
    "    ## while the camera or video is ON\n",
    "while cap.isOpened():\n",
    "    \n",
    "        ## time dilay 0.5 milisecond\n",
    "    time.sleep(0.05)\n",
    "\n",
    "        ## reading the video \n",
    "      ## it will gives us 2 value...... (_) => True or False value .... if it detect the obj then it show True.. otherwise false\n",
    "        ## (frame) => it capture photo from video..... so the photo data will be stored in frame\n",
    "    _, frame  = cap.read()\n",
    "    \n",
    "\n",
    "    ## calling object_data fuction to find the width of the object(pixels) in the frame\n",
    "    object_width_in_frame = object_data(frame)\n",
    "\n",
    "    ## check if the object is zero then don't find the distance ... otherwise run the if loop \n",
    "    if object_width_in_frame != 0:\n",
    "\n",
    "        # finding the distance by calling function \n",
    "        # Distance finder function need \n",
    "        # these arguments the Focal_Length,\n",
    "        # Known_width(centimeters),\n",
    "        # and Known_distance(centimeters)\n",
    "        Distance = Distance_finder(Focal_length_found, KNOWN_WIDTH, object_width_in_frame)\n",
    "\n",
    "        # print(Distance)\n",
    "        \n",
    "        ## draw line as background of text\n",
    "        #cv2.line(frame, (30,30), (230,30), Red, 32)\n",
    "        #cv2.line(frame, (30,30), (230,30), Black, 28)\n",
    "\n",
    "        ## Put text on the screen\n",
    "        cv2.putText(frame, f\"Distance : {round(Distance ,2)} CM\", (70,200), fonts, 0.6, Black, 2)\n",
    "\n",
    "    ## show the frame on the screen\n",
    "    cv2.imshow('window', frame)\n",
    "\n",
    "    ## quit the program by pressing  \"Q\" button\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "## closing the camera\n",
    "cap.release()\n",
    "\n",
    "## closing the windows that are opened\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031ce38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
